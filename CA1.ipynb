{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68001132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, roc_auc_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e1b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "df = pd.read_csv('/Users/sun/Downloads/ca1-dataset.csv')\n",
    "\n",
    "#Assign group\n",
    "group_dict = {}\n",
    "groups = np.array([])\n",
    "for index, row in df.iterrows():\n",
    "    name = row['namea']\n",
    "    if name not in group_dict:\n",
    "        group_dict[name] = index\n",
    "    groups = np.append(groups, group_dict[name])\n",
    "\n",
    "#find no variance data\n",
    "constant_columns = [col for col in df.columns if df[col].nunique() == 1]\n",
    "\n",
    "\n",
    "#drop data&assign x,y\n",
    "df['OffTask'] = df['OffTask'].replace({'Y': 1, 'N': 0})\n",
    "X = df.drop(columns=['OffTask', 'Unique-id', 'namea'] + constant_columns, axis=1)\n",
    "y = df['OffTask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885ed98d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create and fit an XGBoost classifier\u001b[39;00m\n\u001b[1;32m     13\u001b[0m xgb_classifier \u001b[38;5;241m=\u001b[39m XGBClassifier(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m xgb_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[38;5;241m.\u001b[39mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 10 fold\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "\n",
    "kappa_scores = []\n",
    "accuracy_scores = []\n",
    "roc_scores = []\n",
    "\n",
    "for train_index, test_index in gkf.split(X, y, groups=groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Create and fit an XGBoost classifier\n",
    "    xgb_classifier = XGBClassifier(learning_rate=0.1, n_estimators=600, random_state=5)\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "  \n",
    "    # Make predictions\n",
    "    y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate Cohen's Kappa for this fold\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    kappa_scores.append(kappa)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    roc_scores.append(roc)\n",
    "\n",
    "#Calculate the mean Cohen's Kappa score across all folds\n",
    "mean_kappa = sum(kappa_scores) / len(kappa_scores)\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_roc = sum(roc_scores) / len(roc_scores)\n",
    "\n",
    "print(f\"Mean Cohen's Kappa: {mean_kappa:.3f}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean ROC: {mean_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d238e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
